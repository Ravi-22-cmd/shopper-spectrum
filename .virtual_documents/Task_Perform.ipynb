import pandas as pd


df = pd.read_csv("online_retail.csv")


df.head()


df.tail()


df.shape


df.info()


# Remove cancelled invoices (InvoiceNo starts with 'C')
df = df[~df["InvoiceNo"].astype(str).str.startswith("C")]


# Remove rows with missing CustomerID
df = df.dropna(subset=["CustomerID"])



df.iloc[151:157]


# Keep only positive quantity and price
df = df[(df["Quantity"] > 0) & (df["UnitPrice"] > 0)]


df.shape


df.describe()


#                                                                             -----         EDA        ------
# Check date range
df["InvoiceDate"].min(), df["InvoiceDate"].max()


# Total sales by country
df["TotalPrice"] = df["Quantity"] * df["UnitPrice"]

country_sales = (
    df.groupby("Country")["TotalPrice"]
      .sum()
      .sort_values(ascending=False)
)

country_sales.head(10)



# Top selling products by Quantity
top_products_qty = (
    df.groupby("Description")["Quantity"]
      .sum()
      .sort_values(ascending=False)
)

top_products_qty.head(10)



# : Top Products (by Revenue)
top_products_revenue = (
    df.groupby("Description")["TotalPrice"]
      .sum()
      .sort_values(ascending=False)
)

top_products_revenue.head(10)



# Convert to datetime (safe check)
# Time based puchase checked
df["InvoiceDate"] = pd.to_datetime(df["InvoiceDate"])

# Monthly sales
df["Month"] = df["InvoiceDate"].dt.to_period("M")

monthly_sales = df.groupby("Month")["TotalPrice"].sum()
monthly_sales



# Customer level Spending Distribution
customer_spending = (
    df.groupby("CustomerID")["TotalPrice"]
      .sum()
)

customer_spending.describe()


# Trasaction per customer (Frequency Insights)
customer_frequency = (
    df.groupby("CustomerID")["InvoiceNo"]
      .nunique()
)

customer_frequency.describe()



#                            _________________________________ RFM_____________________________...........


# Ensure InvoiceDate is datetime
df["InvoiceDate"] = pd.to_datetime(df["InvoiceDate"])

# Reference date = last date in dataset + 1 day
reference_date = df["InvoiceDate"].max() + pd.Timedelta(days=1)
reference_date



rfm = (
    df.groupby("CustomerID")
      .agg(
          Recency=("InvoiceDate", lambda x: (reference_date - x.max()).days),
          Frequency=("InvoiceNo", "nunique"),
          Monetary=("TotalPrice", "sum")
      )
      .reset_index()
)

rfm.head()



rfm.describe()



rfm.isna().sum()



rfm.sort_values("Monetary", ascending=False).head(10)


#  Tommorow our next step is to perform clustering
# STEP 5: RFM Scaling + KMeans Clustering (Python Coding)
# Is step me hum:
# RFM values ko scale karenge
# Best number of clusters decide karenge
# Customers ko segments me divide karenge


rfm_features = rfm[["Recency", "Frequency", "Monetary"]]


from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm_features)



from sklearn.cluster import KMeans

inertia = []

for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(rfm_scaled)
    inertia.append(kmeans.inertia_)

inertia



from sklearn.metrics import silhouette_score

for k in range(2, 7):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(rfm_scaled)
    score = silhouette_score(rfm_scaled, labels)
    print(f"K={k}, Silhouette Score={score}")



kmeans = KMeans(n_clusters=4, random_state=42)
rfm["Cluster"] = kmeans.fit_predict(rfm_scaled)



cluster_summary = (
    rfm.groupby("Cluster")[["Recency", "Frequency", "Monetary"]]
       .mean()
       .round(2)
)

cluster_summary



cluster_labels = {
    0: "High-Value",
    1: "Regular",
    2: "Occasional",
    3: "At-Risk"
}

rfm["Segment"] = rfm["Cluster"].map(cluster_labels)
rfm.head()



import plotly.express as px

fig = px.scatter(
    rfm,
    x="Recency",
    y="Monetary",
    color="Segment",
    hover_data={
        "CustomerID": True,
        "Frequency": True,
        "Recency": True,
        "Monetary": ":.2f"
    },
    title="Customer Segmentation • Recency vs Monetary",
    template="plotly_dark",
    size="Monetary",
    size_max=18,
)

fig.update_layout(
    title_x=0.5,
    font=dict(size=13),
    legend_title_text="Customer Segment",
    xaxis_title="Recency (Days since last purchase)",
    yaxis_title="Total Spending",
)

fig.show()



fig = px.scatter(
    rfm,
    x="Frequency",
    y="Monetary",
    color="Segment",
    hover_data={
        "CustomerID": True,
        "Recency": True,
        "Frequency": True,
        "Monetary": ":.2f"
    },
    title="Customer Segmentation • Frequency vs Monetary",
    template="plotly_dark",
    size="Frequency",
    size_max=20,

)

fig.update_layout(
    title_x=0.5,
    font=dict(size=13),
    legend_title_text="Customer Segment",
    xaxis_title="Purchase Frequency",
    yaxis_title="Total Spending",


)


fig.show()



fig = px.scatter_3d(
    rfm,
    x="Recency",
    y="Frequency",
    z="Monetary",
    color="Segment",
    hover_data={
        "CustomerID": True,
        "Recency": True,
        "Frequency": True,
        "Monetary": ":.2f"
    },
    title="3D RFM Customer Segmentation",
    template="plotly_dark",
    opacity=0.8
)

fig.update_layout(
    title_x=0.5,
    scene=dict(
        xaxis_title="Recency (Days)",
        yaxis_title="Frequency",
        zaxis_title="Monetary Value",
        xaxis=dict(backgroundcolor="rgb(20,20,20)"),
        yaxis=dict(backgroundcolor="rgb(20,20,20)"),
        zaxis=dict(backgroundcolor="rgb(20,20,20)")
    ),
    font=dict(size=12)
)

fig.show()



# Customer-Product purchase matrix
customer_product_matrix = (
    df.pivot_table(
        index="CustomerID",
        columns="Description",
        values="Quantity",
        aggfunc="sum",
        fill_value=0
    )
)

customer_product_matrix.head()



from sklearn.metrics.pairwise import cosine_similarity

# Transpose: product x customer
product_customer_matrix = customer_product_matrix.T

# Cosine similarity between products
product_similarity = cosine_similarity(product_customer_matrix)

# Convert to DataFrame
product_similarity_df = pd.DataFrame(
    product_similarity,
    index=product_customer_matrix.index,
    columns=product_customer_matrix.index
)

product_similarity_df.head()



def recommend_products(product_name, top_n=5):
    if product_name not in product_similarity_df.index:
        return "Product not found in dataset."
    
    similar_products = (
        product_similarity_df[product_name]
        .sort_values(ascending=False)
        .iloc[1:top_n+1]
    )
    
    return similar_products



recommend_products("WHITE HANGING HEART T-LIGHT HOLDER")
 # streamlit run app.py



